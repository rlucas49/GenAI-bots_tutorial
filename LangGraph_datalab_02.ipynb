{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf4adfc-e37c-4dc2-a37e-13fac3006236",
   "metadata": {},
   "source": [
    "# This is a workbook to explore LangGraph\n",
    "#### Used as resource: https://www.datacamp.com/tutorial/langgraph-tutorial\n",
    "#### Must update pip to get the installs to be compatible with each other\n",
    "#### It works on Datalab. Reconfiguring will be needed for use on other platform.\n",
    "#### Created Sept 15, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d75c5a-e9cd-412c-b30d-c0f756bd8f86",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 311,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (25.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "Successfully installed pip-25.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc794592-8f1d-4797-9983-3748ab8b4f2d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 362,
    "lastExecutedAt": 1758062767011,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "!pip --version",
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 25.2 from /home/repl/.local/lib/python3.10/site-packages/pip (python 3.10)\n"
     ]
    }
   ],
   "source": [
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "119cf9bc-b7d8-42da-8bd0-a8911c3d68b5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11940,
    "lastExecutedAt": 1758062781049,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# pip installs needed\n!pip install langgraph langchain-core langchain-community langchain_openai duckduckgo-search",
    "outputsMetadata": {
     "0": {
      "height": 565,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.1.53)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.0.38)\n",
      "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
      "Collecting duckduckgo-search\n",
      "  Downloading duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.7-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pydantic>=2.7.4 (from langgraph)\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from langgraph) (3.5.0)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10.15)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core)\n",
      "  Downloading langsmith-0.4.28-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.12)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain<2.0.0,>=0.3.27 (from langchain-community)\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting requests<3,>=2.32.5 (from langchain-community)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain<2.0.0,>=0.3.27->langchain-community)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.7.4->langgraph)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.7.4->langgraph)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.5->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.5->langchain-community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting openai<2.0.0,>=1.104.2 (from langchain_openai)\n",
      "  Downloading openai-1.107.3-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain_openai) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.14.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.8)\n",
      "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
      "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (5.3.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.3.45->langchain-core) (1.0.0)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.3.45->langchain-core)\n",
      "  Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)\n",
      "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
      "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.7-py3-none-any.whl (54 kB)\n",
      "Downloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
      "Downloading openai-1.107.3-py3-none-any.whl (947 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m947.6/947.6 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
      "Downloading langsmith-0.4.28-py3-none-any.whl (384 kB)\n",
      "Downloading ormsgpack-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
      "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0mmm\n",
      "\u001b[?25hInstalling collected packages: zstandard, typing-inspection, requests, pydantic-core, primp, ormsgpack, pydantic, duckduckgo-search, pydantic-settings, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain_openai, langgraph-prebuilt, langchain, langgraph, langchain-community\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/20\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "crewai 0.30.11 requires langchain<0.2.0,>=0.1.10, but you have langchain 0.3.27 which is incompatible.\n",
      "embedchain 0.1.113 requires langchain<0.2.0,>=0.1.4, but you have langchain 0.3.27 which is incompatible.\n",
      "embedchain 0.1.113 requires langchain-openai<0.2.0,>=0.1.7, but you have langchain-openai 0.3.33 which is incompatible.\n",
      "langchain-cohere 0.1.5 requires langchain-core<0.3,>=0.1.42, but you have langchain-core 0.3.76 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed duckduckgo-search-8.1.1 langchain-0.3.27 langchain-community-0.3.29 langchain-core-0.3.76 langchain-text-splitters-0.3.11 langchain_openai-0.3.33 langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.7 langsmith-0.4.28 openai-1.107.3 ormsgpack-1.10.0 primp-0.15.0 pydantic-2.11.9 pydantic-core-2.33.2 pydantic-settings-2.10.1 requests-2.32.5 typing-inspection-0.4.1 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "# pip installs needed\n",
    "!pip install langgraph langchain-core langchain-community langchain_openai duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1344f3-5de5-44ca-a1a0-852af7462c62",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 5234,
    "lastExecutedAt": 1758062786801,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import libraries\nfrom typing import TypedDict\nfrom langchain_core.messages import HumanMessage\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, START, END"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from typing import TypedDict\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79e6d7ca-bf9d-4411-897d-07d06f5d4cc0",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1758063021100,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Typed Dict Example\n\nclass PersonDictionary(TypedDict):\n    name:str\n    age:int\n    is_student:bool\n\n# Create a typed dictionary\nour_person: PersonDictionary = {\n    \"name\": \"James\",\n    \"age\":    25,\n    \"is_student\": True\n}\nour_person #Just to check"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'James', 'age': 25, 'is_student': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Typed Dict Example\n",
    "\n",
    "class PersonDictionary(TypedDict):\n",
    "    name:str\n",
    "    age:int\n",
    "    is_student:bool\n",
    "\n",
    "# Create a typed dictionary\n",
    "our_person: PersonDictionary = {\n",
    "    \"name\": \"James\",\n",
    "    \"age\":    25,\n",
    "    \"is_student\": True\n",
    "}\n",
    "our_person #Just to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab90cdf-1306-4bf4-95bd-2049b19177d8",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1758063036868,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Include OpenAI API key here (including in the environment)\nimport os\nprint(os.getcwd())\nprint(os.listdir())\n# print(os.environ[\"OPENAI_API_KEY\"]) #To use with Datalab, create an environment variable\nopenai_api_key = os.environ[\"OPENAI_API_KEY\"]",
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/files/workspace\n",
      "['notebook.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# Include OpenAI API key here (including in the environment)\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.listdir())\n",
    "# print(os.environ[\"OPENAI_API_KEY\"]) #To use with Datalab, create an environment variable\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244abe3f-97b5-4280-afc6-70c7f129be71",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 8,
    "lastExecutedAt": 1758063042418,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "api_key = os.environ.get('OPENAI_API_KEY')\n\nif api_key:\n    print(f\"API Key: present\")\nelse:\n    print(\"API key not found in environment variables.\")",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: present\n"
     ]
    }
   ],
   "source": [
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "if api_key:\n",
    "    print(f\"API Key: present\")\n",
    "else:\n",
    "    print(\"API key not found in environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3daacba8-4993-4895-ae48-ab487cb78042",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 429,
    "lastExecutedAt": 1758063050565,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Define the state of the Agent\nclass AgentState(TypedDict):\n    user_message: HumanMessage\n\nllm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.7)\n# See model pricing (and names) here: https://platform.openai.com/docs/pricing?latest-pricing=standard\n\n#Create the first node - purpose is to pass the user's message to the LLM\ndef first_node(state: AgentState) -> AgentState:\n    response = llm.invoke(state[\"user_message\"])\n    print(f\"\\nAI: {response.content}\")\n    return state"
   },
   "outputs": [],
   "source": [
    "# Define the state of the Agent\n",
    "class AgentState(TypedDict):\n",
    "    user_message: HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.7)\n",
    "# See model pricing (and names) here: https://platform.openai.com/docs/pricing?latest-pricing=standard\n",
    "\n",
    "#Create the first node - purpose is to pass the user's message to the LLM\n",
    "def first_node(state: AgentState) -> AgentState:\n",
    "    response = llm.invoke(state[\"user_message\"])\n",
    "    print(f\"\\nAI: {response.content}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c431338e-ed79-4f2e-be49-33dbb3b5a6dd",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 10,
    "lastExecutedAt": 1758063063862,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Build a graph\ngraph= StateGraph(AgentState)\ngraph.add_node(\"node1\", first_node) # Name of the node on the graph, name of the underlying function\ngraph.add_edge(START, \"node1\")\ngraph.add_edge(\"node1\", END)\nagent = graph.compile()"
   },
   "outputs": [],
   "source": [
    "#Build a graph\n",
    "graph= StateGraph(AgentState)\n",
    "graph.add_node(\"node1\", first_node) # Name of the node on the graph, name of the underlying function\n",
    "graph.add_edge(START, \"node1\")\n",
    "graph.add_edge(\"node1\", END)\n",
    "agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5167cd10-2028-48db-81cd-1e9c821ae2e5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 57,
    "lastExecutedAt": 1758063067256,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from IPython.display import Image, display\ndisplay(Image(agent.get_graph().draw_mermaid_png()))"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44511b7a-2231-4abd-807a-5699bf3ff38c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 565,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter: Should I brush my teeth?\n",
      "\n",
      "AI: Yes. Brushing your teeth regularly is important for cavity prevention, gum health, and fresh breath.\n",
      "\n",
      "What to do:\n",
      "- Frequency and duration: Brush twice a day for about 2 minutes each time.\n",
      "- Toothpaste: Use fluoride toothpaste. For kids, use a smaller amount (pea-sized); adults use a normal pea-sized dab.\n",
      "- Technique: Use a soft-bristled brush. Gentle circular or short back-and-forth strokes on all surfaces (outer, inner, chewing). Don’t scrub hard. Brush your tongue or use a tongue scraper too.\n",
      "- Surfaces to clean: All teeth surfaces, plus the gumline. Don’t forget the back teeth.\n",
      "- After brushing: Spit out excess toothpaste and, if possible, don’t rinse heavily with water right away so fluoride stays on your teeth a bit longer.\n",
      "- Brush replacement: Replace your toothbrush every 3–4 months or sooner if the bristles fray. If you have braces or dental work, you may need to replace more often.\n",
      "\n",
      "Extras that help:\n",
      "- Floss daily to clean between teeth.\n",
      "- Mouthwash is optional. If you use it, choose fluoride-containing and alcohol-free if you have sensitivity.\n",
      "- Limit sugary/acidic foods and drinks; rinse with water after consuming them.\n",
      "- Visit a dentist regularly (usually every 6 months) for checkups and cleanings.\n",
      "\n",
      "If you have specific needs (braces, sensitive teeth, gum bleeding, or a history of cavities), I can tailor the routine. Do you want tips for a particular situation or more practical steps for your current routine?\n",
      "Enter: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Enter: \")\n",
    "    if user_input != \"exit\":\n",
    "        agent.invoke({\"user_message\": [HumanMessage(content=user_input)]})\n",
    "    else:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
