{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf4adfc-e37c-4dc2-a37e-13fac3006236",
   "metadata": {},
   "source": [
    "# Creating Gen AI Agents with LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b66b79-13a0-4f8a-9783-60bd700a70c4",
   "metadata": {},
   "source": [
    "This notebook is used to create 6 different GenAI agents using OpenAI or Ollama models.\n",
    "\n",
    "### It runs on Datalab. Reconfiguring will be needed for use on other platforms.\n",
    "\n",
    "Notes:\n",
    "Must update pip to get the installs to be compatible with each other\n",
    "\n",
    "Make sure there is money in the OpenAI or Ollama account in order to run(https://platform.openai.com/usage)\n",
    "\n",
    "References\n",
    "https://platform.openai.com/docs/overview\n",
    "https://www.datacamp.com/tutorial/langgraph-tutorial\n",
    "#### Created Sept 19, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d75c5a-e9cd-412c-b30d-c0f756bd8f86",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 311,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (25.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "Successfully installed pip-25.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc794592-8f1d-4797-9983-3748ab8b4f2d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 25.0.1 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n"
     ]
    }
   ],
   "source": [
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119cf9bc-b7d8-42da-8bd0-a8911c3d68b5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 13622,
    "lastExecutedAt": 1758744176511,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# pip installs needed\n!pip install langgraph langchain-core langchain-community langchain_openai duckduckgo-search -U ddgs",
    "outputsMetadata": {
     "0": {
      "height": 518,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.1.53)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.0.38)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting duckduckgo-search\n",
      "  Downloading duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting ddgs\n",
      "  Downloading ddgs-9.6.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pydantic>=2.7.4 (from langgraph)\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from langgraph) (3.5.0)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core)\n",
      "  Downloading langsmith-0.4.30-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (23.2)\n",
      "Collecting langchain<2.0.0,>=0.3.27 (from langchain-community)\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.38)\n",
      "Collecting requests<3,>=2.32.5 (from langchain-community)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.12)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
      "Collecting openai<2.0.0,>=1.104.2 (from langchain_openai)\n",
      "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.8)\n",
      "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
      "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (5.3.1)\n",
      "Collecting lxml>=5.3.0 (from duckduckgo-search)\n",
      "  Downloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting httpx>=0.28.1 (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.8.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.14.0)\n",
      "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting brotli (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting h2<5,>=3 (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading h2-4.3.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain<2.0.0,>=0.3.27->langchain-community)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.3.45->langchain-core) (1.0.0)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.3.45->langchain-core)\n",
      "  Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.7.4->langgraph)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.7.4->langgraph)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.5->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.2.2)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.0.0)\n",
      "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
      "Downloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
      "Downloading duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
      "Downloading ddgs-9.6.0-py3-none-any.whl (41 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langsmith-0.4.30-py3-none-any.whl (386 kB)\n",
      "Downloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m195.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m145.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading h2-4.3.0-py3-none-any.whl (61 kB)\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading ormsgpack-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mmm\n",
      "\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: brotli, zstandard, typing-inspection, socksio, requests, pydantic-core, primp, ormsgpack, lxml, hyperframe, hpack, pydantic, httpx, h2, duckduckgo-search, pydantic-settings, openai, langsmith, langgraph-sdk, langchain-core, ddgs, langgraph-checkpoint, langchain-text-splitters, langchain_openai, langgraph-prebuilt, langchain, langgraph, langchain-community\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "crewai 0.30.11 requires langchain<0.2.0,>=0.1.10, but you have langchain 0.3.27 which is incompatible.\n",
      "embedchain 0.1.113 requires langchain<0.2.0,>=0.1.4, but you have langchain 0.3.27 which is incompatible.\n",
      "embedchain 0.1.113 requires langchain-openai<0.2.0,>=0.1.7, but you have langchain-openai 0.3.33 which is incompatible.\n",
      "langchain-cohere 0.1.5 requires langchain-core<0.3,>=0.1.42, but you have langchain-core 0.3.76 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed brotli-1.1.0 ddgs-9.6.0 duckduckgo-search-8.1.1 h2-4.3.0 hpack-4.1.0 httpx-0.28.1 hyperframe-6.1.0 langchain-0.3.27 langchain-community-0.3.29 langchain-core-0.3.76 langchain-text-splitters-0.3.11 langchain_openai-0.3.33 langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 langsmith-0.4.30 lxml-6.0.2 openai-1.109.1 ormsgpack-1.10.0 primp-0.15.0 pydantic-2.11.9 pydantic-core-2.33.2 pydantic-settings-2.11.0 requests-2.32.5 socksio-1.0.0 typing-inspection-0.4.1 zstandard-0.25.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# pip installs needed\n",
    "!pip install langgraph langchain-core langchain-community langchain_openai duckduckgo-search -U ddgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ada3c-0d0a-4ec3-a35a-c064d2c83bb2",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 8,
    "lastExecutedAt": 1758064990923,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "## Agent #1"
   },
   "source": [
    "# Agent #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1344f3-5de5-44ca-a1a0-852af7462c62",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 5234,
    "lastExecutedAt": 1758062786801,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import libraries\nfrom typing import TypedDict\nfrom langchain_core.messages import HumanMessage\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, START, END"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from typing import TypedDict\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79e6d7ca-bf9d-4411-897d-07d06f5d4cc0",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1758063021100,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Typed Dict Example\n\nclass PersonDictionary(TypedDict):\n    name:str\n    age:int\n    is_student:bool\n\n# Create a typed dictionary\nour_person: PersonDictionary = {\n    \"name\": \"James\",\n    \"age\":    25,\n    \"is_student\": True\n}\nour_person #Just to check"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'James', 'age': 25, 'is_student': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Typed Dict Example\n",
    "\n",
    "class PersonDictionary(TypedDict):\n",
    "    name:str\n",
    "    age:int\n",
    "    is_student:bool\n",
    "\n",
    "# Create a typed dictionary\n",
    "our_person: PersonDictionary = {\n",
    "    \"name\": \"James\",\n",
    "    \"age\":    25,\n",
    "    \"is_student\": True\n",
    "}\n",
    "our_person #Just to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab90cdf-1306-4bf4-95bd-2049b19177d8",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1563,
    "lastExecutedAt": 1758071471304,
    "lastExecutedByKernel": "16e01e39-9b33-40c0-aec1-1f30e0e238fe",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Include OpenAI API key here (including in the environment)\nimport os\nprint(os.getcwd())\nprint(os.listdir())\n# print(os.environ[\"OPENAI_API_KEY\"]) #To use with Datalab, create an environment variable\nopenai_api_key = os.environ[\"OPENAI_API_KEY\"]",
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/files/workspace\n",
      "['notebook.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# Include OpenAI API key here (including in the environment)\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.listdir())\n",
    "# print(os.environ[\"OPENAI_API_KEY\"]) #To use with Datalab, create an environment variable\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244abe3f-97b5-4280-afc6-70c7f129be71",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 50,
    "lastExecutedAt": 1758071471354,
    "lastExecutedByKernel": "16e01e39-9b33-40c0-aec1-1f30e0e238fe",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "api_key = os.environ.get('OPENAI_API_KEY')\n\nif api_key:\n    print(f\"API Key: present\")\nelse:\n    print(\"API key not found in environment variables.\")",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: present\n"
     ]
    }
   ],
   "source": [
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "if api_key:\n",
    "    print(f\"API Key: present\")\n",
    "else:\n",
    "    print(\"API key not found in environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3daacba8-4993-4895-ae48-ab487cb78042",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 429,
    "lastExecutedAt": 1758063050565,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Define the state of the Agent\nclass AgentState(TypedDict):\n    user_message: HumanMessage\n\nllm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.7)\n# See model pricing (and names) here: https://platform.openai.com/docs/pricing?latest-pricing=standard\n\n#Create the first node - purpose is to pass the user's message to the LLM\ndef first_node(state: AgentState) -> AgentState:\n    response = llm.invoke(state[\"user_message\"])\n    print(f\"\\nAI: {response.content}\")\n    return state"
   },
   "outputs": [],
   "source": [
    "# Define the state of the Agent\n",
    "class AgentState(TypedDict):\n",
    "    user_message: HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.7)\n",
    "# See model pricing (and names) here: https://platform.openai.com/docs/pricing?latest-pricing=standard\n",
    "\n",
    "#Create the first node - purpose is to pass the user's message to the LLM\n",
    "def first_node(state: AgentState) -> AgentState:\n",
    "    response = llm.invoke(state[\"user_message\"])\n",
    "    print(f\"\\nAI: {response.content}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c431338e-ed79-4f2e-be49-33dbb3b5a6dd",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 10,
    "lastExecutedAt": 1758063063862,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Build a graph\ngraph= StateGraph(AgentState)\ngraph.add_node(\"node1\", first_node) # Name of the node on the graph, name of the underlying function\ngraph.add_edge(START, \"node1\")\ngraph.add_edge(\"node1\", END)\nagent = graph.compile()"
   },
   "outputs": [],
   "source": [
    "#Build a graph\n",
    "graph= StateGraph(AgentState)\n",
    "graph.add_node(\"node1\", first_node) # Name of the node on the graph, name of the underlying function\n",
    "graph.add_edge(START, \"node1\")\n",
    "graph.add_edge(\"node1\", END)\n",
    "agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5167cd10-2028-48db-81cd-1e9c821ae2e5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 57,
    "lastExecutedAt": 1758063067256,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from IPython.display import Image, display\ndisplay(Image(agent.get_graph().draw_mermaid_png()))"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44511b7a-2231-4abd-807a-5699bf3ff38c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1224066,
    "lastExecutedAt": 1758064300164,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "while True:\n    user_input = input(\"Enter: \")\n    if user_input != \"exit\":\n        agent.invoke({\"user_message\": [HumanMessage(content=user_input)]})\n    else:\n        break",
    "outputsMetadata": {
     "0": {
      "height": 517,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter: Should I brush my teeth?\n",
      "\n",
      "AI: Yes. Brushing your teeth regularly is important for cavity prevention, gum health, and fresh breath.\n",
      "\n",
      "What to do:\n",
      "- Frequency and duration: Brush twice a day for about 2 minutes each time.\n",
      "- Toothpaste: Use fluoride toothpaste. For kids, use a smaller amount (pea-sized); adults use a normal pea-sized dab.\n",
      "- Technique: Use a soft-bristled brush. Gentle circular or short back-and-forth strokes on all surfaces (outer, inner, chewing). Don’t scrub hard. Brush your tongue or use a tongue scraper too.\n",
      "- Surfaces to clean: All teeth surfaces, plus the gumline. Don’t forget the back teeth.\n",
      "- After brushing: Spit out excess toothpaste and, if possible, don’t rinse heavily with water right away so fluoride stays on your teeth a bit longer.\n",
      "- Brush replacement: Replace your toothbrush every 3–4 months or sooner if the bristles fray. If you have braces or dental work, you may need to replace more often.\n",
      "\n",
      "Extras that help:\n",
      "- Floss daily to clean between teeth.\n",
      "- Mouthwash is optional. If you use it, choose fluoride-containing and alcohol-free if you have sensitivity.\n",
      "- Limit sugary/acidic foods and drinks; rinse with water after consuming them.\n",
      "- Visit a dentist regularly (usually every 6 months) for checkups and cleanings.\n",
      "\n",
      "If you have specific needs (braces, sensitive teeth, gum bleeding, or a history of cavities), I can tailor the routine. Do you want tips for a particular situation or more practical steps for your current routine?\n",
      "Enter: Who made you?\n",
      "\n",
      "AI: I was created by OpenAI, a research organization. I’m based on the GPT family of models and were trained by a team of engineers and researchers using a mix of licensed data, data created by human trainers, and publicly available data. If you want, I can share more about how I’m trained or how I work.\n",
      "Enter: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      4\u001b[0m         agent\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_message\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39muser_input)]})\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Agent #1 \n",
    "## Very basic - created in an infinite loop for demonstration purposes\n",
    "while True:\n",
    "    user_input = input(\"Enter: \")\n",
    "    if user_input != \"exit\":\n",
    "        agent.invoke({\"user_message\": [HumanMessage(content=user_input)]})\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038fd548-7c49-456b-9b1f-d5f5b8459960",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "source": [
    "# Agent #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "840e69e9-35e8-446d-9160-1fa74611317a",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 9,
    "lastExecutedAt": 1758065040804,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Agent #2\n\n# Import additional libraries in addition to those in Cell #4\n# Import libraries\nimport os\nfrom typing import TypedDict, List, Union\nfrom langchain_core.messages import HumanMessage, AIMessage, SystemMessage\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, START, END"
   },
   "outputs": [],
   "source": [
    "#Agent #2\n",
    "# (This agent creates memory by writing to a text file [the text stays in memory in the current version])\n",
    "\n",
    "# Import additional libraries in addition to those in Cell #4\n",
    "# Import libraries\n",
    "import os\n",
    "from typing import TypedDict, List, Union\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# NOTE: SystemMessage applies to every single response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c9262ac-1f91-4fef-b48c-cd759b79406b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 8,
    "lastExecutedAt": 1758064518579,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "def myfunction(value: Union[int, float]):\n    return value"
   },
   "outputs": [],
   "source": [
    "def myfunction(value: Union[int, float]):\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23f97580-e843-4128-b0c4-aece022067e4",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1758066593675,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "class AgentState(TypedDict):\n    messages: List[Union[HumanMessage, AIMessage, SystemMessage]]\n\nllm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.7)\n# See model pricing (and names) here: https://platform.openai.com/docs/pricing?latest-pricing=standard\n\n# This is the list we will use to store our conversation\nconversation_history = [SystemMessage(content=\"You are an AI assistant that speaks like a pirate. Answer all of my questions properly.\")]\n\n#Create the a new node - purpose is to pass the user's message to the LLM\ndef our_processing_node(state: AgentState) -> AgentState:\n    response = llm.invoke(state[\"messages\"])\n    state[\"messages\"].append(AIMessage(content = response.content)) #This creates the 'memory'\n    print(f\"\\nAI: {response.content}\")\n    print(f\"\\nOur current state looks like: {state['messages']}\")\n    return state"
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: List[Union[HumanMessage, AIMessage, SystemMessage]]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.7)\n",
    "# See model pricing (and names) here: https://platform.openai.com/docs/pricing?latest-pricing=standard\n",
    "\n",
    "# This is the list we will use to store our conversation\n",
    "conversation_history = [SystemMessage(content=\"You are an AI assistant that speaks like a pirate. Answer all of my questions properly.\")]\n",
    "\n",
    "#Create the a new node - purpose is to pass the user's message to the LLM\n",
    "def our_processing_node(state: AgentState) -> AgentState:\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    state[\"messages\"].append(AIMessage(content = response.content)) #This creates the 'memory'\n",
    "    print(f\"\\nAI: {response.content}\")\n",
    "    print(f\"\\nOur current state looks like: {state['messages']}\") # including for debugging\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b708e46-d779-49ed-a185-a3b8e391f761",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 10,
    "lastExecutedAt": 1758065396618,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Build a graph to represent the 2nd Agent\ngraph= StateGraph(AgentState)\ngraph.add_node(\"llm_node\", our_processing_node) # Name of the node on the graph, name of the underlying function\ngraph.add_edge(START, \"llm_node\")\ngraph.add_edge(\"llm_node\", END)\nagent = graph.compile()"
   },
   "outputs": [],
   "source": [
    "#Build a graph to represent the 2nd Agent\n",
    "graph= StateGraph(AgentState)\n",
    "graph.add_node(\"llm_node\", our_processing_node) # Name of the node on the graph, name of the underlying function\n",
    "graph.add_edge(START, \"llm_node\")\n",
    "graph.add_edge(\"llm_node\", END)\n",
    "agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd17a294-ddf3-46fb-be72-5a20cb9e8a2e",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1758065540172,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from IPython.display import Image, display\ndisplay(Image(agent.get_graph().draw_mermaid_png()))"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd199f8a-22cb-4377-b752-62e87e5a3e6b",
   "metadata": {
    "collapsed": true,
    "executionCancelledAt": null,
    "executionTime": 110481,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "lastExecutedAt": 1758066784332,
    "lastExecutedByKernel": "3254b685-5018-4f72-89a3-d9f49ec74668",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Run Agent #2\nwhile True:\n    user_input = input(\"Ask a question: \")\n    conversation_history.append(HumanMessage(content = user_input))\n    result = agent.invoke({\"messages\": conversation_history})\n    conversation_history = result[\"messages\"]\n    # break  #Including for debugging",
    "outputsMetadata": {
     "0": {
      "height": 565,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask a question: Hi, my name is Rich and I want to know if I should continue to learn about using LLMs.\n",
      "\n",
      "AI: Arrr, Rich! Ye’ve got good compass iron in yer eye shipshape: keep chartin’ the seas o’ LLMs. Here be why ye should keep learnin’ and a rough plan to set ye on course.\n",
      "\n",
      "Why ye should keep learnin’ about LLMs\n",
      "- The sails are ever billowin’: LLMs are shifting how many trades do their work, from coding to writing to data wranglin’. If ye learn the ropes, ye’ll have a skill that stays valuable.\n",
      "- It’s a mighty low-barrier-to-start: ye can tinker with APIs, prompts, and small apps without a fleet o’ gold.\n",
      "- It pays to be shipshape on safety and ethics: knowing how to handle bias, hallucinations, and guardrails is a prized cargo.\n",
      "- It unlocks practical power: automate drudgework, build chatty assistants, summarize scrolls, search fleets o’ docs, and more.\n",
      "\n",
      "A quick gut-check: what be yer goal?\n",
      "- Do ye want to build things (apps, tools, chatbots)?\n",
      "- Do ye want to optimize workflows in a job or business?\n",
      "- Do ye want to study the theory for research or teaching?\n",
      "\n",
      "If ye want a plan, here be a simple 4-week voyage (with optional sails if ye crave deeper waters):\n",
      "\n",
      "4-week plan to get ye shipshape\n",
      "Week 1: Foundations and hands-on tinkering\n",
      "- Learn the core terms: tokens, prompts, completions, context windows, safety.\n",
      "- Do 3 small prompt experiments: simple Q&A, a rewrite task, and a structured data extraction.\n",
      "- Pick a single API (OpenAI, Cohere, or an open-source model) and try a basic chat prompt.\n",
      "Week 2: Prompt engineering and reliability\n",
      "- Study prompt patterns: system prompts, few-shot examples, chain-of-thought prompts, and role-play prompts.\n",
      "- Build a few prompts for common tasks in yer field (summarizing reports, extracting key actions, simple reasoning).\n",
      "- Start tracking results: successes, failures, and any hallucinations.\n",
      "Week 3: Tools and orchestration\n",
      "- Try a small toolkit like LangChain or a simple wrapper to chain prompts (input -> tool -> output).\n",
      "- Build a tiny “mini-app”: a prompt-driven assistant that fetches data, summarizes it, and presents a short answer.\n",
      "- Learn about safety guardrails: redact sensitive data, avoid unsafe prompts, and log decisions.\n",
      "Week 4: Project and evaluation\n",
      "- Pick a real-use case: a chat helper for yer hobby or work, a document summarizer, or a data lookup assistant.\n",
      "- Build, test, and iterate. Define success metrics (accuracy, usefulness, safety events).\n",
      "- Document what ye learned and plan next steps.\n",
      "\n",
      "If ye want deeper waters (optional 5–6 weeks)\n",
      "- Deep dive into model behavior: bias, reliability, drift, and evaluation methods.\n",
      "- Learn about memory and context management, retrieval-augmented generation (RAG), and data provenance.\n",
      "- Explore local/offline model options or open-source stacks (for more control).\n",
      "\n",
      "Things ye can do today (quick-start actions)\n",
      "- Pick a goal: “build a tiny helper for summarizing documents” or “a chatbot that answers questions about my work.”\n",
      "- Sign up for a free or trial API and run a couple of prompts gaily: ask for a summary, then compare several rewrites.\n",
      "- Try a simple prompt pattern: system prompt to set role, a few-shot example, then your question.\n",
      "- Note down what worked and what didn’t, especially any off-the-rails answers.\n",
      "\n",
      "What would ye like to focus on?\n",
      "- If ye tell me yer field or what ye hope to build or optimize, I’ll tailor a 2–4 week plan geared to yer sails and crew.\n",
      "\n",
      "Fair winds, Rich. Shall we chart a course tailored to yer goals, matey?\n",
      "Ask a question: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run Agent #2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAsk a question: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     conversation_history\u001b[38;5;241m.\u001b[39mappend(HumanMessage(content \u001b[38;5;241m=\u001b[39m user_input))\n\u001b[1;32m      5\u001b[0m     result \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: conversation_history})\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Run Agent #2\n",
    "while True:\n",
    "    user_input = input(\"Ask a question: \")\n",
    "    conversation_history.append(HumanMessage(content = user_input))\n",
    "    result = agent.invoke({\"messages\": conversation_history})\n",
    "    conversation_history = result[\"messages\"]\n",
    "    # break  #Including for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6224c94-707d-45f0-a703-94bb35dc0321",
   "metadata": {},
   "source": [
    "### BUT, including memory above means more tokens will be used and it will cost more. A solution could be to include only the last 5 messages (recency bias)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e1eb1-00c8-4bf9-8601-1711664c56f1",
   "metadata": {},
   "source": [
    "# Agent #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e459a88-2b26-482e-962a-99f8945eb7c9",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1758073897569,
    "lastExecutedByKernel": "16e01e39-9b33-40c0-aec1-1f30e0e238fe",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Agent #3\n# (built with In-built tools)\n# This is a true 'agent'\n\nfrom typing import TypedDict, Annotated, Sequence\nfrom langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage\n# BaseMessage is like the parent class\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, END\nfrom langgraph.graph.message import add_messages\nfrom langgraph.prebuilt import ToolNode\nfrom langchain_community.tools import DuckDuckGoSearchRun"
   },
   "outputs": [],
   "source": [
    "# Agent #3\n",
    "# (built with In-built tools)\n",
    "# This is a true 'agent'\n",
    "# It's called a 'ReAct Agent'. It stands for reasoning and acting agent.\n",
    "\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage\n",
    "# BaseMessage is like the parent class\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_community.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "097e10ac-b763-4e02-9f62-486d358584f4",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1758072064149,
    "lastExecutedByKernel": "16e01e39-9b33-40c0-aec1-1f30e0e238fe",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "x: Annotated[int, \"age\"] = 20\n# Note: Annotated allows us to include extra information with a variable"
   },
   "outputs": [],
   "source": [
    "x: Annotated[int, \"age\"] = 20\n",
    "# Note: Annotated allows us to include extra information with a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d6c1342-e7b8-45fa-be4e-9f2568094da3",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1758072066401,
    "lastExecutedByKernel": "16e01e39-9b33-40c0-aec1-1f30e0e238fe",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "numbers: Sequence[int] = [1,2,3]\n#Note: A Sequence allows read-only access to any ordered data type (i.e. list, tuple, str). It is used when you only need to read data, not modify it.\n#Note: a list is mutable. It's an ordered data type, but you can change it."
   },
   "outputs": [],
   "source": [
    "numbers: Sequence[int] = [1,2,3]\n",
    "#Note: A Sequence allows read-only access to any ordered data type (i.e. list, tuple, str). It is used when you only need to read data, not modify it.\n",
    "#Note: a list is mutable. It's an ordered data type, but you can change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee91ddfe-4118-40f7-8afe-7fe0b84f5d45",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 517,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI:  content='The Kansas City Chiefs won Super Bowl LVIII (played February 11, 2024, in Las Vegas), defeating the San Francisco 49ers 25–22. Patrick Mahomes was named the Super Bowl MVP.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1078, 'prompt_tokens': 16, 'total_tokens': 1094, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1024, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CGbFaD7RGsFEHUcXXTIwYDGUwPILH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--1469a072-762a-4cc6-bd3f-38a8f54a17be-0' usage_metadata={'input_tokens': 16, 'output_tokens': 1078, 'total_tokens': 1094, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1024}}\n",
      "\n",
      "SEARCH:  Feb 16, 2025 — Super Bowl LIX was an American football championship game played between the National Football Conference (NFC) champion Philadelphia Eagles and the ... Dallas' Larry Brown , a 12th-round draft pick, who was still grieving the death of his infant son two and a half months prior, 6 7 became the first ... The Eagles were trying to win their first NFL title since 1960 and the first championship for the city of Philadelphia since Moses Malone 's \"fo', fi ... Feb 9, 2025 — Patrick Mahomes and company took down the 49ers 25-22 in overtime, leading to the team's second-straight Super Bowl victory. Feb 9, 2025 — Who won the Super Bowl in 2024? The Chiefs came out on top in Super Bowl 58 against the 49ers with a 25-22 overtime win at Allegiant Stadium in Las Vegas.\n"
     ]
    }
   ],
   "source": [
    "# Use the In-built DuckDuckGo search tool\n",
    "query = \"Who won the 2024 NFL Superbowl?\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.7)\n",
    "print(\"\\nAI: \", llm.invoke(query))\n",
    "\n",
    "search = DuckDuckGoSearchRun() # Search tool\n",
    "print(\"\\nSEARCH: \", search.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "807a6399-c87f-4b24-8183-3b9241f5a298",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 13,
    "lastExecutedAt": 1758075993534,
    "lastExecutedByKernel": "16e01e39-9b33-40c0-aec1-1f30e0e238fe",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "class AgentState(TypedDict):\n    messages: Annotated[Sequence[BaseMessage], add_messages] # Reducer Function - essentially allows for the addition of messages without getting deleted AND IT ADDS A BIT MORE INFORMATION\n\ntools = [DuckDuckGoSearchRun()] #We create a list of tools we want our Agent to have access to\n\nllm = ChatOpenAI(model = \"gpt-5-nano\").bind_tools(tools) #How to give the LLM knowledge about these tools\n\n#Below is a node\ndef model_call(state: AgentState) -> AgentState:\n    system_prompt = SystemMessage(content = \n            \"You are my AI assistant, please answer my query to the best of your ability.\")\n    response = llm.invoke([system_prompt] + state[\"messages\"]) #SEnding both the SystemMessage and the current state \n    return {\"messages\": [response]}\n    "
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages] # Reducer Function - essentially allows for the addition of messages without getting deleted AND IT ADDS A BIT MORE INFORMATION\n",
    "\n",
    "tools = [DuckDuckGoSearchRun()] #We create a list of tools we want our Agent to have access\n",
    "# There are many more tools available. See LangChain Documentation/Tools/Toolkits (there are both free and paid tools)\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-5-nano\").bind_tools(tools) #How to give the LLM knowledge about/from the tools defined above\n",
    "\n",
    "#Below is a node\n",
    "def model_call(state: AgentState) -> AgentState:\n",
    "    system_prompt = SystemMessage(content = \n",
    "            \"You are my AI assistant, please answer my query to the best of your ability.\")\n",
    "    response = llm.invoke([system_prompt] + state[\"messages\"]) #SEnding both the SystemMessage and the current state \n",
    "    return {\"messages\": [response]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03c879a4-0675-4d37-be5a-455f0a98d4ec",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 50,
    "lastExecutedAt": 1758076012945,
    "lastExecutedByKernel": "16e01e39-9b33-40c0-aec1-1f30e0e238fe",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Underlying action behind the conditional edge\ndef should_continue(state: AgentState):\n    messages = state[\"messages\"] #Copies the latest state into the 'message' variable \n    last_message = messages[-1] #only looks at the last message\n\n    # This code checks if there is any further tool calling required in the last message\n    if not last_message.tool_calls:\n        return \"end\"\n    else:\n        return \"continue\"\n\n# Create the graph\ngraph = StateGraph(AgentState)\ngraph.add_node(\"agent3\", model_call)\n\ntool_node = ToolNode(tools=tools) #Here we create a node that neatly contains all of the tools we want the agent to have\ngraph.add_node(\"tools\", tool_node)\n\ngraph.set_entry_point(\"agent3\")\n\n# Create a conditional edge\ngraph.add_conditional_edges(\n    \"agent3\", #Origin\n    should_continue, #underlying action\n    { # Different edges along with their destinations\n        \"continue\": \"tools\",\n        \"end\": END,\n    },\n)\n\ngraph.add_edge(\"tools\", \"agent3\")\n\napp = graph.compile()"
   },
   "outputs": [],
   "source": [
    "#Underlying action behind the conditional edge (this is a decision funtion)\n",
    "def should_continue(state: AgentState):\n",
    "    messages = state[\"messages\"] #Copies the latest state into the 'message' variable \n",
    "    last_message = messages[-1] #only looks at the last message\n",
    "\n",
    "    # This code checks if there is any further tool calling required in the last message\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "# Create the graph\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"agent3\", model_call)\n",
    "\n",
    "# A tool node is needed. Create it here.\n",
    "tool_node = ToolNode(tools=tools) #Here we create a node that neatly contains all of the tools we want the agent to have\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph.set_entry_point(\"agent3\") # Need to define the start and end point. END is line 28\n",
    "\n",
    "# Create a conditional edge\n",
    "graph.add_conditional_edges(\n",
    "    \"agent3\", #Origin\n",
    "    should_continue, #underlying action\n",
    "    { # Different edges along with their destinations\n",
    "        \"continue\": \"tools\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"tools\", \"agent3\") # this edge goes from the tools node back to agent3. Super important in order to create a loop.\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1915894-9b2b-4bd6-85f0-b789c13470ce",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 42,
    "lastExecutedAt": 1758076022355,
    "lastExecutedByKernel": "16e01e39-9b33-40c0-aec1-1f30e0e238fe",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from IPython.display import Image, display\ndisplay(Image(app.get_graph().draw_mermaid_png()))"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88b63fab-8c81-4574-b460-335ad16304c9",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 517,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who won the 2025 Champions League?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  duckduckgo_search (call_daDo8rGR1QqDg8ryASy6R0YP)\n",
      " Call ID: call_daDo8rGR1QqDg8ryASy6R0YP\n",
      "  Args:\n",
      "    query: 2025 UEFA Champions League winner\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: duckduckgo_search\n",
      "\n",
      "The 2025 UEFA Champions League final was the final match of the 2024–25 UEFA Champions League , the 70th season of Europe's premier club football tournament organised by UEFA , and the 33rd season since it was renamed from the European Champion Cl... This is the overview which provides the most important informations on the competition UEFA Champions League in the season 25/26.Galatasaray Turkish cup winner 2025 Turkish Champion 2025 . UEFA Champions League 2025 /2026 scores, live results, standings. UEFA Champions League . 2025 /2026. Summary Results Fixtures Standings Archive. What is the prize money for the UEFA Champions League ? Clubs involved in the league phase of the 2025 -26 Champions League will have $2.6bn distributed among them. The winner of the Champions League , along with all other teams, will be rewarded on a game-by-game basis.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  duckduckgo_search (call_bk6u5YGLEYYsxblg3BvHhqBI)\n",
      " Call ID: call_bk6u5YGLEYYsxblg3BvHhqBI\n",
      "  Args:\n",
      "    query: 2025 UEFA Champions League winner final\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: duckduckgo_search\n",
      "\n",
      "The 2025 UEFA Champions League final will be the final match of the 2024–25 UEFA Champions League , the 70th season of Europe's premier club ... The 2024 UEFA Champions League final was the final match of the 2023–24 UEFA Champions League , the 69th season of Europe's premier club football ... The 2024 UEFA Champions League final was the last match of the 2023–24 UEFA Champions League , which is a big football competition in Europe. It was held at the Allianz Arena in Munich, Germany, on 31 May 2025, between French club Paris Saint-Germain and Italian club Inter Milan. Paris Saint-Germain won the match 5–0 for their first European Cup title, [5] marking the second final victory by a French club since Marseille in 1993. View all 2 days ago · In 2025/26, Europe's elite club competition returns for its 71st season and its 34th since it was renamed the UEFA Champions League . It kicked off on 8 July 2025 and runs until the final in ... 1 day ago · PSG win their first UEFA Champions League title in 2025, beating Inter Milan 5-0. Know results , new format, key highlights, and 2025-26 season dates May 31, 2025 · Who won the UEFA Champions League final 2025? Paris Saint-Germain won the 2025 Champions League final after an astonishing 5-0 victory over Inter Milan in the final in Munich. May 31, 2025 · Paris Saint-Germain crushed Inter Milan 5-0 in the 2025 UEFA Champions League final at Allianz Arena in Munich, Germany, on Saturday to secure the top title in European soccer for the first time... View all Jun 23, 2025 · Discover all the details about the 2025 UEFA Champions League Final between PSG and Inter Milan , including the date, venue, kick-off time, and broadcast information for this historic clash. The final of the 2025 Champions League was played on 31 May 2025 at Allianz Arena in Munich, Germany. The match was played between French club Paris Saint-Germain and Italian club Inter Milan. PSG won 5-0. The 2025 UEFA Champions League final will be the final match of the 2024 – 25 UEFA Champions League , the 70th season of Europe's premier club ...\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Paris Saint-Germain (PSG) won the 2025 UEFA Champions League. They defeated Inter Milan 5-0 in the final, played on May 31, 2025, at the Allianz Arena in Munich, Germany. It was PSG’s first Champions League title. If you’d like, I can pull up sources or details from the final.\n"
     ]
    }
   ],
   "source": [
    "# Function to make the output more aesthetic\n",
    "# Use this block again to improve output presentation\n",
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "query = \"Who won the 2025 Champions League?\"\n",
    "inputs = {\"messages\": [(\"user\", query)]}\n",
    "print_stream(app.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9cea0f-6f53-485b-81d1-fe5d8c95a3db",
   "metadata": {},
   "source": [
    "# Agent #4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3b3ce-1b22-4345-87a5-7f5cfd8feab6",
   "metadata": {},
   "source": [
    "This is another ReAct agent, just with fewer lines of code.\n",
    "It's actually the exact same agent as Agent #3, just with fewer lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543fef44-1e17-4f52-9013-9be879001d53",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 5136,
    "lastExecutedAt": 1758744182987,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from langgraph.prebuilt import create_react_agent #Method to create ReAct agent easily\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.messages import HumanMessage\nfrom langchain_community.tools import DuckDuckGoSearchRun"
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent #Method to create ReAct agent easily\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa937151-2e1b-4e4f-8401-2c9138f3f4f0",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 13025,
    "lastExecutedAt": 1758744291498,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Define tools we will pass to agent.\n# Also define the agent\ntools = [DuckDuckGoSearchRun()]\n\nllm = ChatOpenAI(model=\"gpt-5-nano\")\n\nagent = create_react_agent(\n    model = llm,\n    tools = tools,\n    name = \"search_agent\",\n    prompt = \"You are my AI assistant that has access to certain tools. Use the tools to help me with my tasks.\", # Basic prompt    \n)\n\nquery = \"Who won the 2025 Champions League?\"\n\nresult = agent.invoke ({\n    \"messages\": [{\"role\": \"user\",\n                  \"content\": query}]\n})"
   },
   "outputs": [],
   "source": [
    "# Define tools we will pass to agent.\n",
    "# Also define the agent\n",
    "tools = [DuckDuckGoSearchRun()]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model = llm,\n",
    "    tools = tools,\n",
    "    name = \"search_agent\",\n",
    "    prompt = \"You are my AI assistant that has access to certain tools. Use the tools to help me with my tasks.\", # Basic prompt    \n",
    ")\n",
    "\n",
    "query = \"Who won the 2025 Champions League?\"\n",
    "\n",
    "result = agent.invoke ({\n",
    "    \"messages\": [{\"role\": \"user\",\n",
    "                  \"content\": query}]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "753cd5b0-9cc3-4d55-80ab-d1f488fe855d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 164,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Calls: \n",
      "  Tool: duckduckgo_search, Args: {'query': '2025 UEFA Champions League winner'}\n",
      "/nFinal Answer:\n",
      "Paris Saint-Germain (PSG) won the 2025 UEFA Champions League, beating Inter Milan 5-0 in the final at the Allianz Arena in Munich on May 31, 2025. It was PSG’s first Champions League title. Want me to pull up sources or more details (top scorers, lineup, etc.)?\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "for msg in result[\"messages\"]:\n",
    "    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "        print(\"Tool Calls: \")\n",
    "        for call in msg.tool_calls:\n",
    "            print(f\"  Tool: {call['name']}, Args: {call['args']}\")\n",
    "\n",
    "# Print the final answer\n",
    "print(\"/nFinal Answer:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1686cf04-5f8e-4bc8-acc8-7dc477702c5a",
   "metadata": {},
   "source": [
    "# Agent #5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59b662-1889-44db-9f97-e8f1d8c7824c",
   "metadata": {},
   "source": [
    "Demo of how to make our own tools. After all, LangGraph won't have all of the tools we will need already built-in and ready to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37aafb05-5987-4c6a-99ba-9ffadc528e0a",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 8,
    "lastExecutedAt": 1758744692764,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# All libraries needed for Agent #5\nfrom langchain_core.tools import tool\nfrom langgraph.prebuilt import create_react_agent #Method to create ReAct agent easily\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.messages import HumanMessage\nfrom langchain_community.tools import DuckDuckGoSearchRun\nfrom datetime import datetime"
   },
   "outputs": [],
   "source": [
    "# All libraries needed for Agent #5\n",
    "from langchain_core.tools import tool # Use this line to define a custom tool\n",
    "from langgraph.prebuilt import create_react_agent #Method to create ReAct agent easily\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ec817b-3cdd-43cc-8480-10f76f4fe0a5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 12,
    "lastExecutedAt": 1758744877221,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Create a simple tool that tells us the weather in a US city\n\n@tool # This is a decorator, and tells LangGraph that this is a special function (it is a tool)\ndef weather(city: str) -> str:\n    \"\"\"Get the weather in a given city\"\"\"\n    return f\"The weather in {city} is summy\""
   },
   "outputs": [],
   "source": [
    "# Create a simple tool that tells us the weather in a US city\n",
    "\n",
    "@tool # This is a decorator, and tells LangGraph that this is a special function (it is a custom tool)\n",
    "def weather(city: str) -> str:\n",
    "    \"\"\"Get the weather in a given city\"\"\" ## MUST HAVE THIS DocString. It tells the agent what the tool is for so it knows how to use the custom tool.\n",
    "    return f\"The weather in {city} is summy\" #hard-coding the answer to see if this gets passed along (I spelled sunny wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3862c4b4-da65-470f-a43d-d847485d023a",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1758744949866,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "tools = [weather] #Our weather tool now goes into the list of tools"
   },
   "outputs": [],
   "source": [
    "tools = [weather] #Our weather tool now goes into the list of tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bf63263-a4e8-4c70-bd94-5f52e2fbeef9",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 15,
    "lastExecutedAt": 1758746851869,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "llm = ChatOpenAI(model=\"gpt-5-nano\")\n\n# Creating th ReAct Agent with a custom tool\\\nagent = create_react_agent(\n    model = llm,\n    tools = tools,\n    name = \"weater_agent\",\n    prompt = \"You are my AI assistant that has access to certain tools. Use the tools to help me with my tasks.\", # Basic prompt \n)"
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "\n",
    "# Creating th ReAct Agent with a custom tool\\\n",
    "agent = create_react_agent(\n",
    "    model = llm,\n",
    "    tools = tools,\n",
    "    name = \"weater_agent\",\n",
    "    prompt = \"You are my AI assistant that has access to certain tools. Use the tools to help me with my tasks.\", # Basic prompt \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c412ff90-c5b0-4ab3-a36d-cd2e0f701519",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 311,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "\n",
      "Final Answer:\n",
      "The weather in Phoenix is sunny right now. Would you like current temperature, humidity, wind, or a 7-day forecast?\n"
     ]
    }
   ],
   "source": [
    "# Obtain the result\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": f\"What is the weather in Phoenix?\"}]\n",
    "})\n",
    "\n",
    "# Printing the final answer and making it more readable:\n",
    "for msg in result[\"messages\"]:\n",
    "    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "        print(\"Tool Calls:\")\n",
    "        for call in msg.tool_calls:\n",
    "            print(f\"  Tool: {call['name']}, Args: {call['args']}\")\n",
    "\n",
    "# Print the final answer\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d4b075-85fd-4db9-aa62-52ef704b3af3",
   "metadata": {},
   "source": [
    "#### We can input as many tools as we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa3bdeb8-3ec2-43d4-ba53-15eaf118b7bf",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 50,
    "lastExecutedAt": 1758747501690,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Update the docstring to define more tools\n\n@tool\ndef social_media_follwer_count(social_media: str) -> str:\n    \"\"\" Retrieves the current follower count for a specified social media platform.\n    \n    Args:\n        social_media (str): The name of the social media platform (e.g. 'twitter', 'instagram', 'linkedin')\n        \n    Returns:\n        str: The follower count as a formatted string\n        \n    Example:\n        >>> social_media_follower_count('twitter')\n        '1,234 followers'\n    \"\"\"\n\n    return f\"You have 9876 followers on {social_media}\""
   },
   "outputs": [],
   "source": [
    "# Update the docstring to define more tools\n",
    "\n",
    "@tool\n",
    "def social_media_follwer_count(social_media: str) -> str:\n",
    "    \"\"\" Retrieves the current follower count for a specified social media platform.\n",
    "    \n",
    "    Args:\n",
    "        social_media (str): The name of the social media platform (e.g. 'twitter', 'instagram', 'linkedin')\n",
    "        \n",
    "    Returns:\n",
    "        str: The follower count as a formatted string\n",
    "        \n",
    "    Example:\n",
    "        >>> social_media_follower_count('twitter')\n",
    "        '1,234 followers'\n",
    "    \"\"\"\n",
    "\n",
    "    return f\"You have 9876 followers on {social_media}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d86d66a4-0e0b-4130-b51e-d075070dfb74",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 17,
    "lastExecutedAt": 1758747505553,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Define the tools list\ntools = [weather, social_media_follwer_count]\nllm = ChatOpenAI(model=\"gpt-5-nano\")\n\n# Creating the ReAct Agent with our custom tools\nagent = create_react_agent(\n    model = llm,\n    tools = tools,\n    name = \"general_agent\",\n    prompt = \"You are my AI assistant that has access to certain tools. Use the tools to help me with my tasks.\", # Basic prompt \n)"
   },
   "outputs": [],
   "source": [
    "# Define the tools list\n",
    "tools = [weather, social_media_follwer_count]\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "\n",
    "# Creating the ReAct Agent with our custom tools\n",
    "agent = create_react_agent(\n",
    "    model = llm,\n",
    "    tools = tools,\n",
    "    name = \"general_agent\",\n",
    "    prompt = \"You are my AI assistant that has access to certain tools. Use the tools to help me with my tasks.\", # Basic prompt \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d851de10-fa0a-4928-8544-d9556ae6b0f8",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 332,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "  Tool: social_media_follwer_count, Args: {'social_media': 'LinkedIn'}\n",
      "  Tool: social_media_follwer_count, Args: {'social_media': 'Instagram'}\n",
      "\n",
      "Final Answer:\n",
      "Here are the results:\n",
      "\n",
      "- Weather in Phoenix: summy (looks like a typo—likely meant \"sunny\"). I can re-fetch the current conditions to confirm and get a forecast if you’d like.\n",
      "- LinkedIn followers: 9,876\n",
      "- Instagram followers: 9,876\n",
      "\n",
      "Would you like me to pull the latest forecast for Phoenix or refresh the weather data to confirm?\n"
     ]
    }
   ],
   "source": [
    "# Obtain the result\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": f\"What is the weather in Phoenix? How many followers do I have on LinkedIn? What about Instagram?\"}]\n",
    "})\n",
    "\n",
    "# Printing the final answer and making it more readable:\n",
    "for msg in result[\"messages\"]:\n",
    "    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "        print(\"Tool Calls:\")\n",
    "        for call in msg.tool_calls:\n",
    "            print(f\"  Tool: {call['name']}, Args: {call['args']}\")\n",
    "\n",
    "# Print the final answer\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601ab871-41bd-4118-82dd-e73be05be245",
   "metadata": {},
   "source": [
    "# Agent #6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7fc6a3-4bf9-47bd-89a8-90f6443c395c",
   "metadata": {},
   "source": [
    "#### Use an Ollama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b18ce010-71ae-4490-9281-5ec93911512b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 518,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain_ollama\n",
      "  Downloading langchain_ollama-0.3.8-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting ollama<1.0.0,>=0.5.3 (from langchain_ollama)\n",
      "  Downloading ollama-0.5.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.76 in /home/repl/.local/lib/python3.10/site-packages (from langchain_ollama) (0.3.76)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/repl/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.76->langchain_ollama) (0.4.30)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_ollama) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_ollama) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_ollama) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_ollama) (23.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/repl/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.76->langchain_ollama) (2.11.9)\n",
      "Requirement already satisfied: httpx>=0.27 in /home/repl/.local/lib/python3.10/site-packages (from ollama<1.0.0,>=0.5.3->langchain_ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain_ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain_ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain_ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain_ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain_ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain_ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_ollama) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_ollama) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/repl/.local/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_ollama) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/repl/.local/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_ollama) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/repl/.local/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/repl/.local/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_ollama) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_ollama) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_ollama) (2.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain_ollama) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain_ollama) (1.3.1)\n",
      "Downloading langchain_ollama-0.3.8-py3-none-any.whl (25 kB)\n",
      "Downloading ollama-0.5.4-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama, langchain_ollama\n",
      "Successfully installed langchain_ollama-0.3.8 ollama-0.5.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a224fb69-99e1-451d-9fd3-7fe5a7fb3ced",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 141,
    "lastExecutedAt": 1758748120790,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import the libraries needed for Agent #6\nfrom langchain_core.tools import tool # Use this line to define a custom tool\nfrom langgraph.prebuilt import create_react_agent #Method to create ReAct agent easily\nfrom langchain_openai import ChatOpenAI\nfrom langchain_ollama import ChatOllama\nfrom langchain_core.messages import HumanMessage\nfrom langchain_community.tools import DuckDuckGoSearchRun\nfrom datetime import datetime"
   },
   "outputs": [],
   "source": [
    "# Import the libraries needed for Agent #6\n",
    "from langchain_core.tools import tool # Use this line to define a custom tool\n",
    "from langgraph.prebuilt import create_react_agent #Method to create ReAct agent easily\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fec345ce-9b09-4de0-8b10-8cb1b6086201",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 53,
    "lastExecutedAt": 1758748243198,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Create a simple tool that tells us the weather in a US city\n\n@tool # This is a decorator, and tells LangGraph that this is a special function (it is a custom tool)\ndef weather(city: str) -> str:\n    \"\"\"Get the weather in a given city\"\"\" ## MUST HAVE THIS DocString. It tells the agent what the tool is for so it knows how to use the custom tool.\n    return f\"The weather in {city} is rainy\" #hard-coding the answer. This is the result if the search cannot find any other result."
   },
   "outputs": [],
   "source": [
    "# Create a simple tool that tells us the weather in a US city\n",
    "\n",
    "@tool # This is a decorator, and tells LangGraph that this is a special function (it is a custom tool)\n",
    "def weather(city: str) -> str:\n",
    "    \"\"\"Get the weather in a given city\"\"\" ## MUST HAVE THIS DocString. It tells the agent what the tool is for so it knows how to use the custom tool.\n",
    "    return f\"The weather in {city} is rainy\" #hard-coding the answer. This is the result if the search cannot find any other result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a6bb68a-c4ed-4a98-9bb8-3dc9dcff09d0",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 97,
    "lastExecutedAt": 1758749564282,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "tools = [weather, DuckDuckGoSearchRun()]\n\nllm_ollama = ChatOllama(model=\"define_me\")\nllm_openai = ChatOpenAI(model=\"gpt-5-nano\")\n\ndate = datetime.now().strftime(\"%Y-%m-%d\") #Tells us the current date and time"
   },
   "outputs": [],
   "source": [
    "tools = [weather, DuckDuckGoSearchRun()]\n",
    "\n",
    "llm_ollama = ChatOllama(model=\"define_me\")\n",
    "llm_openai = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "\n",
    "date = datetime.now().strftime(\"%Y-%m-%d\") #Tells us the current date and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "130acac0-0c86-4620-a704-2cc6258b3ec4",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 16,
    "lastExecutedAt": 1758749570648,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Define the OpenAI ReAct Agent\n\n# Creating the ReAct Agent with the custom tools\nopenai_agent = create_react_agent(\n    model = llm_openai,\n    tools = tools,\n    name = \"general_agent\",\n    prompt = \"You are my AI assistant that has access to certain tools. Use the tools to help me with my tasks.\", # Basic prompt \n)"
   },
   "outputs": [],
   "source": [
    "# Define the OpenAI ReAct Agent\n",
    "\n",
    "# Creating the ReAct Agent with the custom tools\n",
    "openai_agent = create_react_agent(\n",
    "    model = llm_openai,\n",
    "    tools = tools,\n",
    "    name = \"general_agent\",\n",
    "    prompt = \"You are my AI assistant that has access to certain tools. Use the tools to help me with my tasks.\", # Basic prompt \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76a597db-1b39-4e43-a4a0-6a8409ea3a26",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 518,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- OpenAI Agent Results ---\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'Alimentation Couche-Tard stock price today ATD.B'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'Alimentation Couche-Tard stock performance last 7 days'}\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'Alimentation Couche-Tard stock price today'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'Alimentation Couche-Tard stock performance last 7 days'}\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.B stock price today Sep 24 2025'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD stock performance last 7 days Sep 2025'}\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.B stock price today Sep 24, 2025'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.B stock performance last 7 days Sep 2025'}\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.TO stock price today Sep 24 2025'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.TO stock performance last 7 days Sep 2025'}\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.TO stock price today Sep 24 2025'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.TO stock performance last 7 days Sep 2025'}\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.TO price Sep 24 2025'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'Alimentation Couche-Tard ATD last 7 days Sep 2025'}\n",
      "Tool Calls:\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.TO stock price Sep 24 2025'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.TO stock performance last 7 days Sep 2025'}\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.TO Sep 24 2025 stock price'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.TO 7 day stock performance Sep 2025'}\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.TO stock price Sep 24 2025'}\n",
      "  Tool: duckduckgo_search, Args: {'query': 'ATD.TO last 7 days Sep 2025'}\n",
      "Tool Calls:\n",
      "  Tool: weather, Args: {'city': 'Phoenix'}\n",
      "\n",
      "Final Answer (OpenAI):\n",
      "Here’s a concise update on each part of your request:\n",
      "\n",
      "- Weather in Phoenix: It’s rainy right now.\n",
      "\n",
      "- Circle K stock information (as of today, 2025-09-24) and its performance over the past week:\n",
      "  - I’m not seeing a clear, consistent source in my current results for a Circle K brand-specific stock. Circle K is a private brand operated by Alimentation Couche-Tard (ATD) in many markets, and ATD is publicly traded (TSX: ATD, ATD.TO). There isn’t a separate public “Circle K stock” ticker. If you’re asking about ATD (Alimentation Couche-Tard), I can provide today’s ATD price and its 7-day performance if you’d like. Otherwise, Circle K itself doesn’t have a standalone public listing.\n",
      "  - If you want ATD data: I can pull the latest price for ATD (TSX) and summarize its performance over the last 7 days. Do you want me to fetch that now?\n",
      "\n",
      "- What today is:\n",
      "  - Today is September 24, 2025.\n",
      "\n",
      "- List of tools I have access to:\n",
      "  - Weather (to fetch weather by city)\n",
      "  - DuckDuckGo search (for web results and current info)\n",
      "  - Multi-tool wrapper (multi_tool_use) to run multiple tools in parallel\n",
      "\n",
      "Would you like me to fetch the latest ATD/ATD.TO price and 7-day performance now, and also confirm Circle K market info from ATD? If you have a preferred exchange (TSX, NASDAQ ADR, etc.), tell me and I’ll tailor the data.\n"
     ]
    }
   ],
   "source": [
    "# Execute the OpenAI Agent\n",
    "print(\"\\n--- OpenAI Agent Results ---\")\n",
    "openai_result = openai_agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": f\"What is the weather in Phoenix? Tell me about the stock of 3M as of today {date} and how the stock has performed in the past week. Tell me what today is. Also tell me a list of tools you have please.\"}]\n",
    "})\n",
    "\n",
    "# Printing the final answer and making it more readable:\n",
    "for msg in openai_result[\"messages\"]:\n",
    "    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "        print(\"Tool Calls:\")\n",
    "        for call in msg.tool_calls:\n",
    "            print(f\"  Tool: {call['name']}, Args: {call['args']}\")\n",
    "\n",
    "# Print the final answer\n",
    "print(\"\\nFinal Answer (OpenAI):\")\n",
    "print(openai_result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02865d53-4bf5-4c4a-a77a-99e39c11c887",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 16,
    "lastExecutedAt": 1758749913740,
    "lastExecutedByKernel": "99c4256f-1e8e-482e-82c6-6c507179c0c3",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Define the Ollama ReAct Agent\n\n# Creating the ReAct Agent with the custom tools\nollama_agent = create_react_agent(\n    model = llm_ollama,\n    tools = tools,\n    name = \"general_agent\",\n    prompt = \"You are my AI assistant that has access to certain tools. Use the tools to help me with my tasks.\", # Basic prompt \n)"
   },
   "outputs": [],
   "source": [
    "# Define the Ollama ReAct Agent\n",
    "\n",
    "# Creating the ReAct Agent with the custom tools\n",
    "ollama_agent = create_react_agent(\n",
    "    model = llm_ollama,\n",
    "    tools = tools,\n",
    "    name = \"general_agent\",\n",
    "    prompt = \"You are my AI assistant that has access to certain tools. Use the tools to help me with my tasks.\", # Basic prompt \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f55fa-d3f8-4b44-98f5-feb248d81047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the Ollama Agent\n",
    "print(\"\\n--- Ollama Agent Results ---\")\n",
    "ollama_result = ollama_agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": f\"What is the weather in Phoenix? Tell me about the stock of Circle K as of today {date} and how the stock has performed in the past week. Tell me what today is. Also tell me a list of tools you have please.\"}]\n",
    "})\n",
    "\n",
    "# Printing the final answer and making it more readable:\n",
    "for msg in ollama_result[\"messages\"]:\n",
    "    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "        print(\"Tool Calls:\")\n",
    "        for call in msg.tool_calls:\n",
    "            print(f\"  Tool: {call['name']}, Args: {call['args']}\")\n",
    "\n",
    "# Print the final answer\n",
    "print(\"\\nFinal Answer (Ollama_AI):\")\n",
    "print(\"\\n------ This won't actually work because I haven't set up an account with Ollama\")\n",
    "print(ollama_result[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
